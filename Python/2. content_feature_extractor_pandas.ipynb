{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import networkx\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import spacy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gulpease(text):\n",
    "    text = text.strip()\n",
    "    n_phrases = len(text.split('.'))-1\n",
    "    n_words = len(text.split(' '))\n",
    "    text = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "    n_chars = len(text.split())\n",
    "    index = 89+((300*n_phrases-(10*n_chars))/n_words)\n",
    "    return index\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    space_regex = '\\n'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(space_regex, ' ', parsed_text)\n",
    "    #parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    #parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    #parsed_text = parsed_text.code(\"utf-8\", errors='ignore')\n",
    "    return parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./news-dataset.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['body_text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocess_text'] = df['body_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>body_text</th>\n",
       "      <th>publish_data</th>\n",
       "      <th>reliability</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.conoscenzealconfine.it/oms-italia-...</td>\n",
       "      <td>https://www.conoscenzealconfine.it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Conoscenze Al Confine']</td>\n",
       "      <td>OMS: “L’Italia è il banco di prova del Coronav...</td>\n",
       "      <td>https://www.conoscenzealconfine.it/wp-content/...</td>\n",
       "      <td>di Guido da Landriano\\n\\nL’Italia è forse la “...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>di Guido da Landriano L’Italia è forse la “Cav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.ilprimatonazionale.it/politica/cor...</td>\n",
       "      <td>https://www.ilprimatonazionale.it</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>[]</td>\n",
       "      <td>Coronavirus, crolla la fiducia in Conte. Ora è...</td>\n",
       "      <td>https://www.ilprimatonazionale.it/wp-content/u...</td>\n",
       "      <td>Roma, 5 mar – Per mesi e mesi Giuseppe Conte è...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Roma, 5 mar – Per mesi e mesi Giuseppe Conte è...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.ilprimatonazionale.it/cronaca/coro...</td>\n",
       "      <td>https://www.ilprimatonazionale.it</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>[]</td>\n",
       "      <td>Coronavirus, i media esteri all’attacco dell’I...</td>\n",
       "      <td>https://www.ilprimatonazionale.it/wp-content/u...</td>\n",
       "      <td>Roma, 5 mar – Con l’aggravarsi dell’emergenza ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Roma, 5 mar – Con l’aggravarsi dell’emergenza ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ilprimatonazionale.it/cultura/coro...</td>\n",
       "      <td>https://www.ilprimatonazionale.it</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>[]</td>\n",
       "      <td>Il coronavirus un’arma da guerra biologica? Ip...</td>\n",
       "      <td>https://www.ilprimatonazionale.it/wp-content/u...</td>\n",
       "      <td>Roma, 5 mar – La situazione sta, con tutta evi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Roma, 5 mar – La situazione sta, con tutta evi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://it.sputniknews.com/italia/202003088836...</td>\n",
       "      <td>https://it.sputniknews.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Coronavirus, Italia primo Paese al mondo per t...</td>\n",
       "      <td>https://cdnit2.img.sputniknews.com/images/883/...</td>\n",
       "      <td>Al fine di migliorare il funzionamento del sit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Al fine di migliorare il funzionamento del sit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.conoscenzealconfine.it/oms-italia-...   \n",
       "1  https://www.ilprimatonazionale.it/politica/cor...   \n",
       "2  https://www.ilprimatonazionale.it/cronaca/coro...   \n",
       "3  https://www.ilprimatonazionale.it/cultura/coro...   \n",
       "5  https://it.sputniknews.com/italia/202003088836...   \n",
       "\n",
       "                            publisher publish_date                     author  \\\n",
       "0  https://www.conoscenzealconfine.it          NaN  ['Conoscenze Al Confine']   \n",
       "1   https://www.ilprimatonazionale.it   2020-03-05                         []   \n",
       "2   https://www.ilprimatonazionale.it   2020-03-05                         []   \n",
       "3   https://www.ilprimatonazionale.it   2020-03-05                         []   \n",
       "5          https://it.sputniknews.com          NaN                         []   \n",
       "\n",
       "                                               title  \\\n",
       "0  OMS: “L’Italia è il banco di prova del Coronav...   \n",
       "1  Coronavirus, crolla la fiducia in Conte. Ora è...   \n",
       "2  Coronavirus, i media esteri all’attacco dell’I...   \n",
       "3  Il coronavirus un’arma da guerra biologica? Ip...   \n",
       "5  Coronavirus, Italia primo Paese al mondo per t...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://www.conoscenzealconfine.it/wp-content/...   \n",
       "1  https://www.ilprimatonazionale.it/wp-content/u...   \n",
       "2  https://www.ilprimatonazionale.it/wp-content/u...   \n",
       "3  https://www.ilprimatonazionale.it/wp-content/u...   \n",
       "5  https://cdnit2.img.sputniknews.com/images/883/...   \n",
       "\n",
       "                                           body_text  publish_data  \\\n",
       "0  di Guido da Landriano\\n\\nL’Italia è forse la “...           NaN   \n",
       "1  Roma, 5 mar – Per mesi e mesi Giuseppe Conte è...           NaN   \n",
       "2  Roma, 5 mar – Con l’aggravarsi dell’emergenza ...           NaN   \n",
       "3  Roma, 5 mar – La situazione sta, con tutta evi...           NaN   \n",
       "5  Al fine di migliorare il funzionamento del sit...           NaN   \n",
       "\n",
       "   reliability                                    preprocess_text  \n",
       "0            0  di Guido da Landriano L’Italia è forse la “Cav...  \n",
       "1            0  Roma, 5 mar – Per mesi e mesi Giuseppe Conte è...  \n",
       "2            0  Roma, 5 mar – Con l’aggravarsi dell’emergenza ...  \n",
       "3            0  Roma, 5 mar – La situazione sta, con tutta evi...  \n",
       "5            0  Al fine di migliorare il funzionamento del sit...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 10)\n",
      "(2192, 10)\n"
     ]
    }
   ],
   "source": [
    "df_high = df[df.reliability == 1]\n",
    "df_low = df[df.reliability == 0]\n",
    "print(df[df.reliability == 0].shape)\n",
    "print(df[df.reliability == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gulpease Readability Italian Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gulpease'] = df['preprocess_text'].apply(gulpease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_title_stop_nums'] = df['title'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "df['fea_body_stop_nums'] = df['preprocess_text'].apply(lambda x: len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_title_word_nums'] = df['title'].apply(lambda x: len(x.split(' ')))\n",
    "df['fea_body_word_nums'] = df['preprocess_text'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_title_num_nums'] = df['title'].apply(lambda y: len([x for x in y if x.isdigit()]))\n",
    "df['fea_body_num_nums'] = df['preprocess_text'].apply(lambda y: len([x for x in y if x.isdigit()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_low_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_title_chars_low_nums'] = df['title'].apply(lambda y: len([x for x in y if x.islower()]))\n",
    "df['fea_body_chars_low_nums'] = df['preprocess_text'].apply(lambda y: len([x for x in y if x.islower()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_upp_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_title_chars_upp_nums'] = df['title'].apply(lambda y: len([x for x in y if x.isupper()]))\n",
    "df['fea_body_chars_upp_nums'] = df['preprocess_text'].apply(lambda y: len([x for x in y if x.isupper()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_punct_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_title_chars_punct_nums'] = df['title'].apply(lambda y: len([x for x in y if x in string.punctuation]))\n",
    "df['fea_body_chars_punct_nums'] = df['preprocess_text'].apply(lambda y: len([x for x in y if x in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_words title+body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_word_nums'] = df['fea_title_word_nums'] + df['fea_body_word_nums']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "density word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_body_word_density'] = (df['fea_body_chars_low_nums']+df['fea_body_chars_upp_nums']) / (df['fea_body_word_nums']+1)\n",
    "df['fea_title_word_density'] = (df['fea_title_chars_low_nums']+df['fea_title_chars_upp_nums']) / (df['fea_title_word_nums']+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    doc = nlp(x)\n",
    "    for tup in doc:\n",
    "        ppo = tup.pos_\n",
    "        if ppo == flag:\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_noun_count'] = df['preprocess_text'].apply(lambda x: check_pos_tag(x, 'NOUN'))\n",
    "df['body_verb_count'] = df['preprocess_text'].apply(lambda x: check_pos_tag(x, 'VERB'))\n",
    "df['body_adj_count'] = df['preprocess_text'].apply(lambda x: check_pos_tag(x, 'ADJ'))\n",
    "df['body_adv_count'] = df['preprocess_text'].apply(lambda x: check_pos_tag(x, 'ADV'))\n",
    "df['body_pron_count'] = df['preprocess_text'].apply(lambda x: check_pos_tag(x, 'PRON'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_body_total_length'] = df['preprocess_text'].apply(len)\n",
    "df['fea_title_total_length'] = df['title'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upp vs length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_body_upp_vs_length'] = df.apply(lambda row: float(row['fea_body_chars_upp_nums'])/float(row['fea_body_total_length']),axis=1)\n",
    "df['fea_title_upp_vs_length'] = df.apply(lambda row: float(row['fea_title_chars_upp_nums'])/float(row['fea_title_total_length']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exclamation and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_body_num_exclamation_marks'] = df['preprocess_text'].apply(lambda x: x.count('!'))\n",
    "df['fea_body_num_question_marks'] = df['preprocess_text'].apply(lambda x: x.count('?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fea_body_num_unique_words'] = df['preprocess_text'].apply(lambda x: len(set(w for w in x.split())))\n",
    "df['fea_body_words_vs_unique'] = df['fea_body_num_unique_words'] / df['fea_body_word_nums']\n",
    "df['fea_body_word_unique_percent'] =  df['fea_body_num_unique_words']*100/df['fea_body_word_nums']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Feature Matrix to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "content_features = df[['fea_title_word_nums',\n",
    "                       'fea_title_num_nums',\n",
    "                       'fea_title_chars_low_nums',\n",
    "                       'fea_title_chars_upp_nums',\n",
    "                       'fea_title_chars_punct_nums',\n",
    "                       'fea_title_stop_nums',\n",
    "                       'fea_body_word_nums',\n",
    "                       'fea_body_num_nums',\n",
    "                       'fea_body_chars_low_nums',\n",
    "                       'fea_body_chars_upp_nums',\n",
    "                       'fea_body_chars_punct_nums',\n",
    "                       'fea_body_stop_nums',\n",
    "                       'fea_word_nums',\n",
    "                       'fea_body_word_density',\n",
    "                       'fea_title_word_density',\n",
    "                       'body_noun_count',\n",
    "                       'body_verb_count',\n",
    "                       'body_adj_count',\n",
    "                       'body_adv_count',\n",
    "                       'body_pron_count',\n",
    "                       'fea_body_total_length',\n",
    "                       'fea_title_total_length',\n",
    "                       'fea_body_upp_vs_length',\n",
    "                       'fea_title_upp_vs_length',\n",
    "                       'fea_body_num_exclamation_marks',\n",
    "                       'fea_body_num_question_marks',\n",
    "                       'fea_body_num_unique_words',\n",
    "                       'fea_body_words_vs_unique',\n",
    "                       'fea_body_word_unique_percent',\n",
    "                       'gulpease',\n",
    "                       'reliability'\n",
    "                    ]]\n",
    "\n",
    "content_features.to_pickle('./content-features_pandas.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
